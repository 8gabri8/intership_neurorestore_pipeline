{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Multiple Timepoints\n",
    "\n",
    "This script creates plots that summarize the evolution of the density in differt ROIs across differt timepoints. The Region of Injection is keept constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dir of the project (if script is run on batch mode, i.e. for all brains of the project)\n",
    "dir_project = \"/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset\"\n",
    "\n",
    "# Csv file with all the brains data\n",
    "csv_file = \"/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/Results/all_brains.csv\"\n",
    "\n",
    "# number of the ROI to display in a plot\n",
    "n_roi_displayed = 10 \n",
    "\n",
    "# List of region to injection to invesigate (one for each folder in the porject)\n",
    "region_injections = [\"DR\", \"GPi\", \"STN\", \"PARN\", \"IF\", \"GPe\", \"CU\", \"BST\"]\n",
    "# List of Timepoints to investigate\n",
    "timepoints = [\"Uninjured\", \"1 weeks\", \"8 weeks\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data, varname, groupnames):\n",
    "    \"\"\"\n",
    "    Function to calculate the mean and standard error for each group, preserving the original order.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A pandas DataFrame containing the data.\n",
    "    - varname: The name of the column containing the variable to be summarized (string).\n",
    "    - groupnames: A list of column names to be used as grouping variables (list of strings).\n",
    "\n",
    "    Returns:\n",
    "    - data_sum: A pandas DataFrame with mean and standard error for each group, preserving the original order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add an index column to preserve the original order\n",
    "    data['_order'] = range(len(data))\n",
    "    \n",
    "    # Group the data by the specified group names\n",
    "    grouped = data.groupby(groupnames)\n",
    "    \n",
    "    # Calculate the mean and standard error for the specified variable\n",
    "    data_sum = grouped[varname].agg(\n",
    "        mean='mean', \n",
    "        std='std', \n",
    "        count='count'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate standard error\n",
    "    data_sum['sem'] = data_sum['std'] / np.sqrt(data_sum['count'])\n",
    "    \n",
    "    # Merge the summary with the original data to preserve the order\n",
    "    data_sum = pd.merge(data[groupnames + ['_order']], data_sum, on=groupnames).sort_values('_order')\n",
    "\n",
    "    # Check for duplicates in the summary DataFrame\n",
    "    if data_sum.duplicated(subset=groupnames).any():\n",
    "        print(\"Warning: Duplicates found in the summarized data!\")\n",
    "        # Drop duplicates, keeping the first occurrence\n",
    "        data_sum = data_sum.drop_duplicates(subset=groupnames)\n",
    "    \n",
    "    # Sort the summary DataFrame based on the preserved order from the original data\n",
    "    data_sum['_order'] = data.groupby(groupnames)['_order'].first().values\n",
    "    data_sum = data_sum.sort_values('_order')\n",
    "    \n",
    "    # Drop the temporary _order column\n",
    "    data_sum = data_sum.drop(columns=['_order'])\n",
    "    \n",
    "    # Rename the mean and sem columns\n",
    "    data_sum = data_sum.rename(columns={'mean': varname + '_mean', 'sem': varname + '_sem', 'std': varname + '_std'})\n",
    "    \n",
    "    # Drop the 'std' and 'count' columns, as they are not needed\n",
    "    #data_sum = data_sum.drop(columns=['std', 'count'])\n",
    "    \n",
    "    return data_sum\n",
    "\n",
    "def search_injection_folder(base_dir, name_dir_to_search):\n",
    "    \"\"\"\n",
    "    Searches for a subfolder with a specific name within the given base directory.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir: The path of the base directory to search within (string).\n",
    "    - name_dir_to_search: The name of the subfolder to search for (string).\n",
    "\n",
    "    Returns:\n",
    "    - The full path of the subfolder if found, or None if not found.\n",
    "    \"\"\"\n",
    "    # Ensure the base directory exists\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise ValueError(f\"The base directory '{base_dir}' does not exist or is not a directory.\")\n",
    "    \n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if name_dir_to_search in dirs:\n",
    "            # Return the full path to the subfolder\n",
    "            return os.path.join(root, name_dir_to_search)\n",
    "    \n",
    "    # Return None if the subfolder was not found\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv all Brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Timepoints Barplot most dense, different x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Duplicates found in the summarized data!\n",
      "Analyzing data for Region Injection: DR\n",
      "Analyzing data for Region Injection: STN\n",
      "Analyzing data for Region Injection: PARN\n",
      "Analyzing data for Region Injection: IF\n",
      "Analyzing data for Region Injection: GPi\n",
      "Analyzing data for Region Injection: GPe\n",
      "Analyzing data for Region Injection: CU\n",
      "Analyzing data for Region Injection: BST\n"
     ]
    }
   ],
   "source": [
    "# Summarize data\n",
    "df_summary = data_summary(df_all, varname=\"Cell Density\", groupnames=[\"TimePoint\", \"Region Injection\", \"ROI\"])\n",
    "    # in this way I take the mean of:\n",
    "        # the same ROI, coming from mice of the same timepoint and same Region Injection\n",
    "\n",
    "# Loop over each region\n",
    "for region in region_injections:\n",
    "\n",
    "    print(f\"Analyzing data for Region Injection: {region}\")\n",
    "    \n",
    "    # Set up the plot grid\n",
    "    n_plots = len(timepoints)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=n_plots, figsize=(5 * n_plots, 6), sharey=True)\n",
    "    \n",
    "    if n_plots == 1:\n",
    "        axes = [axes]  # Ensure axes is a list even for a single plot\n",
    "    \n",
    "    # Plot for each time point\n",
    "    for i, timepoint in enumerate(timepoints):\n",
    "        \n",
    "        # Filter data for the current time point\n",
    "        t = df_summary[(df_summary[\"TimePoint\"] == timepoint) & (df_summary[\"Region Injection\"] == region)]\n",
    "        \n",
    "        # Sort by mean density and select top ROIs\n",
    "        t_sorted = t.sort_values(by=\"Cell Density_mean\", ascending=False).head(n_roi_displayed)\n",
    "        \n",
    "        # Create the bar plot on the corresponding subplot\n",
    "        axes[i].bar(t_sorted[\"ROI\"], t_sorted[\"Cell Density_mean\"], yerr=t_sorted[\"Cell Density_sem\"], color=\"lightblue\", capsize=5)\n",
    "        axes[i].set_title(f\"{timepoint}\")\n",
    "        axes[i].set_xticks(range(len(t_sorted[\"ROI\"])))  # Set the positions of the ticks\n",
    "        axes[i].set_xticklabels(t_sorted[\"ROI\"], rotation=45, ha='right')  # Set the labels\n",
    "        axes[i].set_ylim(0, 0.02)\n",
    "    \n",
    "    # Set a common y-label\n",
    "    fig.text(0.04, 0.5, 'Cell Density Mean', va='center', rotation='vertical')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0.05, 0, 1, 1])\n",
    "    \n",
    "    # Save the combined plot\n",
    "    injection_folder = search_injection_folder(dir_project, region) # Search the dolfer of the injection\n",
    "    result_folder = os.path.join(injection_folder, \"Results\") \n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "    fig.savefig(os.path.join(result_folder, f\"timepoints_barplot_different_xaxis_{n_roi_displayed}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot Multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Duplicates found in the summarized data!\n",
      "Analyzing baseline Uninjured\n",
      "\tAnalyzing data for Region Injection: DR\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: STN\n",
      "\t\tATTENTION --> No data for Injection Region STN\n",
      "\tAnalyzing data for Region Injection: PARN\n",
      "\t\tATTENTION --> No data for Injection Region PARN\n",
      "\tAnalyzing data for Region Injection: IF\n",
      "\t\tATTENTION --> No data for Injection Region IF\n",
      "\tAnalyzing data for Region Injection: GPi\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: GPe\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: CU\n",
      "\t\tATTENTION --> No data for Injection Region CU\n",
      "\tAnalyzing data for Region Injection: BST\n",
      "\t\tATTENTION --> No data for Injection Region BST\n",
      "\n",
      "\n",
      "Analyzing baseline 1 weeks\n",
      "\tAnalyzing data for Region Injection: DR\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: STN\n",
      "\t\tATTENTION --> No data for Injection Region STN\n",
      "\tAnalyzing data for Region Injection: PARN\n",
      "\t\tATTENTION --> No data for Injection Region PARN\n",
      "\tAnalyzing data for Region Injection: IF\n",
      "\t\tATTENTION --> No data for Injection Region IF\n",
      "\tAnalyzing data for Region Injection: GPi\n",
      "\t\tATTENTION --> No data for baseline 1 weeks in Injection Region GPi\n",
      "\tAnalyzing data for Region Injection: GPe\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: CU\n",
      "\t\tATTENTION --> No data for Injection Region CU\n",
      "\tAnalyzing data for Region Injection: BST\n",
      "\t\tATTENTION --> No data for Injection Region BST\n",
      "\n",
      "\n",
      "Analyzing baseline 8 weeks\n",
      "\tAnalyzing data for Region Injection: DR\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: STN\n",
      "\t\tATTENTION --> No data for Injection Region STN\n",
      "\tAnalyzing data for Region Injection: PARN\n",
      "\t\tATTENTION --> No data for Injection Region PARN\n",
      "\tAnalyzing data for Region Injection: IF\n",
      "\t\tATTENTION --> No data for Injection Region IF\n",
      "\tAnalyzing data for Region Injection: GPi\n",
      "\t\tATTENTION --> No data for baseline 8 weeks in Injection Region GPi\n",
      "\tAnalyzing data for Region Injection: GPe\n",
      "\t\tSuccess!\n",
      "\tAnalyzing data for Region Injection: CU\n",
      "\t\tATTENTION --> No data for Injection Region CU\n",
      "\tAnalyzing data for Region Injection: BST\n",
      "\t\tATTENTION --> No data for Injection Region BST\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summarize data\n",
    "df_summary = data_summary(df_all, varname=\"Cell Density\", groupnames=[\"TimePoint\", \"Region Injection\", \"ROI\"])\n",
    "    # in this way I take the mean of:\n",
    "        # the same ROI, coming from mice of the same timepoint and same Region Injection\n",
    "\n",
    "def multiple_bar_barplot(df_summary, baseline_timepoint = \"Uninjured\"):\n",
    "\n",
    "    print(f\"Analyzing baseline {baseline_timepoint}\")\n",
    "    # Define colors for the timepoints\n",
    "    colors = plt.get_cmap('tab10').colors  # Use the 'tab10' colormap for distinct colors\n",
    "    color_map = {timepoint: colors[i % len(colors)] for i, timepoint in enumerate(timepoints)}\n",
    "        \n",
    "    for region in region_injections:\n",
    "        print(f\"\\tAnalyzing data for Region Injection: {region}\")\n",
    "\n",
    "        # Select only specific region of injection\n",
    "        df_region = df_summary[df_summary[\"Region Injection\"] == region]\n",
    "\n",
    "        if df_region.shape[0] == 0:\n",
    "            print(f\"\\t\\tATTENTION --> No data for Injection Region {region}\")\n",
    "            continue\n",
    "\n",
    "        # Filter data for the baseline case\n",
    "        baseline_data = df_region[df_region[\"TimePoint\"] == baseline_timepoint]\n",
    "\n",
    "        # Find the most dense region for the \"Uninjured\" case\n",
    "        most_dense_regions = baseline_data.sort_values(by=\"Cell Density_mean\", ascending=False).head(n_roi_displayed)\n",
    "        most_dense_region_list = most_dense_regions[\"ROI\"].tolist()\n",
    "        \n",
    "        # Filter data for the specific regions and timepoints\n",
    "        filtered_data = df_region[df_region[\"ROI\"].isin(most_dense_region_list)]\n",
    "\n",
    "        if filtered_data.shape[0] == 0:\n",
    "            print(f\"\\t\\tATTENTION --> No data for baseline {baseline_timepoint} in Injection Region {region}\")\n",
    "            continue\n",
    "\n",
    "        # Pivot data for plotting\n",
    "        pivot_data = filtered_data.pivot_table(index=\"ROI\", columns=\"TimePoint\", values=\"Cell Density_mean\", aggfunc='mean')\n",
    "        pivot_errors = filtered_data.pivot_table(index=\"ROI\", columns=\"TimePoint\", values=\"Cell Density_sem\", aggfunc='mean')\n",
    "\n",
    "        # Ensure columns are ordered by the given timepoints list and include only available timepoints\n",
    "        available_timepoints = [tp for tp in timepoints if tp in pivot_data.columns]\n",
    "        pivot_data = pivot_data[available_timepoints]\n",
    "        pivot_errors = pivot_errors[available_timepoints]\n",
    "\n",
    "        # Ensure order is decreseing based oin baseline timepoint\n",
    "        pivot_data = pivot_data.sort_values(by=baseline_timepoint, ascending=False)\n",
    "        pivot_errors = pivot_errors.sort_values(by=baseline_timepoint, ascending=False)\n",
    "\n",
    "        # Create a single bar plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        pivot_data.plot(kind='bar', yerr=pivot_errors, ax=ax, capsize=5, color=[color_map[timepoint] for timepoint in timepoints])\n",
    "\n",
    "        # Format the plot\n",
    "        ax.set_title(f\"Cell Density for Region Injection: {region} (Top Dense Regions)\")\n",
    "        ax.set_xlabel(\"ROI\")\n",
    "        ax.set_ylabel(\"Cell Density Mean\")\n",
    "        ax.set_xticklabels(pivot_data.index, rotation=45, ha='right')\n",
    "        ax.set_ylim(0, 0.02)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the combined plot\n",
    "        injection_folder = search_injection_folder(dir_project, region) # Search the dolfer of the injection\n",
    "        result_folder = os.path.join(injection_folder, \"Results\") \n",
    "        os.makedirs(result_folder, exist_ok=True)\n",
    "        fig.savefig(os.path.join(result_folder, f\"timepoints_barplot_muultiple_bars_baseline_{baseline_timepoint}_{n_roi_displayed}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "        print(f\"\\t\\tSuccess!\")\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "for t in timepoints:\n",
    "    multiple_bar_barplot(df_summary, baseline_timepoint=t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot LogFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain ID               100       101       602       601       200       201  \\\n",
      "Region Injection        DR        DR        DR        DR        DR        DR   \n",
      "TimePoint          8 weeks   8 weeks Uninjured Uninjured   1 weeks   1 weeks   \n",
      "ROI                                                                            \n",
      "Left: AAA         0.000236  0.000184  0.000236  0.001032  0.000184  0.000158   \n",
      "Left: ACA         0.000285  0.000262  0.000285  0.000214  0.000262  0.000292   \n",
      "Left: ACAd        0.000316  0.000263  0.000316  0.000227  0.000263  0.000283   \n",
      "Left: ACAd1       0.000121  0.000071  0.000121  0.000035  0.000071  0.000142   \n",
      "Left: ACAd2/3     0.000243  0.000202  0.000243  0.000183  0.000202  0.000230   \n",
      "...                    ...       ...       ...       ...       ...       ...   \n",
      "Right: vhc        0.000030  0.000000  0.000030  0.000013  0.000000  0.000063   \n",
      "Right: von        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "Right: vtd        0.002945  0.000000  0.002945  0.008933  0.000000  0.000693   \n",
      "Right: x          0.000630  0.000255  0.000630  0.000468  0.000255  0.000048   \n",
      "Right: y          0.000249  0.000460  0.000249  0.000560  0.000460  0.000217   \n",
      "\n",
      "Brain ID               301       300       579       580       583       400  \\\n",
      "Region Injection       GPe       GPe       GPe       GPe       GPe       GPe   \n",
      "TimePoint          8 weeks   8 weeks Uninjured Uninjured Uninjured   1 weeks   \n",
      "ROI                                                                            \n",
      "Left: AAA         0.000184  0.000236  0.000170  0.000184  0.000158  0.000184   \n",
      "Left: ACA         0.000262  0.000285  0.000290  0.000262  0.000292  0.000262   \n",
      "Left: ACAd        0.000263  0.000316  0.000302  0.000263  0.000283  0.000263   \n",
      "Left: ACAd1       0.000071  0.000121  0.000112  0.000071  0.000142  0.000071   \n",
      "Left: ACAd2/3     0.000202  0.000243  0.000196  0.000202  0.000230  0.000202   \n",
      "...                    ...       ...       ...       ...       ...       ...   \n",
      "Right: vhc        0.000000  0.000030  0.000027  0.000000  0.000063  0.000000   \n",
      "Right: von        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "Right: vtd        0.000000  0.002945  0.000166  0.000000  0.000693  0.000000   \n",
      "Right: x          0.000255  0.000630  0.000247  0.000255  0.000048  0.000255   \n",
      "Right: y          0.000460  0.000249  0.000213  0.000460  0.000217  0.000460   \n",
      "\n",
      "Brain ID               401       596       597  \n",
      "Region Injection       GPe       GPi       GPi  \n",
      "TimePoint          1 weeks Uninjured Uninjured  \n",
      "ROI                                             \n",
      "Left: AAA         0.000158  0.000150  0.000167  \n",
      "Left: ACA         0.000292  0.000274  0.000351  \n",
      "Left: ACAd        0.000283  0.000273  0.000347  \n",
      "Left: ACAd1       0.000142  0.000099  0.000219  \n",
      "Left: ACAd2/3     0.000230  0.000212  0.000324  \n",
      "...                    ...       ...       ...  \n",
      "Right: vhc        0.000063  0.000000  0.000000  \n",
      "Right: von        0.000000  0.000000  0.000000  \n",
      "Right: vtd        0.000693  0.000914  0.000847  \n",
      "Right: x          0.000048  0.000113  0.000153  \n",
      "Right: y          0.000217  0.000305  0.000211  \n",
      "\n",
      "[1680 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all_pivot = df_all.pivot(index=\"ROI\", columns=[\"Brain ID\", \"Region Injection\", \"TimePoint\"], values=\"Cell Density\")\n",
    "    #Attnetion: now the name of a col is a list\n",
    "print(df_all_pivot)\n",
    "#print(df_all_pivot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Region DR\n",
      "\tSaved logFC_1weeks_uninjured for region DR\n",
      "\tSaved logFC_8weeks_1week for region DR\n",
      "\tSaved logFC_8weeks_uninjured for region DR\n",
      "Processing Region GPi\n",
      "\tATTENTION: In comparison logFC_1weeks_uninjured, one TimePoint is Missing.\n",
      "\tATTENTION: In comparison logFC_8weeks_1week, one TimePoint is Missing.\n",
      "\tATTENTION: In comparison logFC_8weeks_uninjured, one TimePoint is Missing.\n",
      "Processing Region STN\n",
      "\tATTNETION: No Samples for region STN\n",
      "Processing Region PARN\n",
      "\tATTNETION: No Samples for region PARN\n",
      "Processing Region IF\n",
      "\tATTNETION: No Samples for region IF\n",
      "Processing Region GPe\n",
      "\tSaved logFC_1weeks_uninjured for region GPe\n",
      "\tSaved logFC_8weeks_1week for region GPe\n",
      "\tSaved logFC_8weeks_uninjured for region GPe\n",
      "Processing Region CU\n",
      "\tATTNETION: No Samples for region CU\n",
      "Processing Region BST\n",
      "\tATTNETION: No Samples for region BST\n"
     ]
    }
   ],
   "source": [
    "logFC_bound = 1000\n",
    "\n",
    "combinations = {\n",
    "    \"logFC_1weeks_uninjured\": [\"1 weeks\", \"Uninjured\"],\n",
    "    \"logFC_8weeks_1week\": [\"8 weeks\", \"1 weeks\"],\n",
    "    \"logFC_8weeks_uninjured\": [\"8 weeks\", \"Uninjured\"]\n",
    "}\n",
    "\n",
    "for i, region in enumerate(region_injections):\n",
    "\n",
    "    print(f\"Processing Region {region}\")\n",
    "\n",
    "    # Select only mice of specific region\n",
    "    ok_cols = [col for col in df_all_pivot.columns if region in col[1]]\n",
    "    df_region = df_all_pivot[ok_cols]\n",
    "\n",
    "    if df_region.empty:\n",
    "        print(f\"\\tATTENTION: No Samples for region {region}\")\n",
    "        continue\n",
    "\n",
    "    #print(df_region)\n",
    "\n",
    "    for key, (treatment, baseline) in combinations.items(): \n",
    "\n",
    "        treatment_cols = [col for col in df_region.columns if treatment in col[2]] #Yake the cols (i.e mice) of tretment cpnditon\n",
    "        baseline_cols = [col for col in df_region.columns if baseline in col[2]]\n",
    "\n",
    "        df_treatment = df_region[treatment_cols]\n",
    "        df_baseline = df_region[baseline_cols]\n",
    "\n",
    "        #print(df_treatment)\n",
    "\n",
    "        if df_treatment.empty or df_baseline.empty:\n",
    "            print(f\"\\tATTENTION: In comparison {key}, one TimePoint is Missing.\")\n",
    "            continue\n",
    "\n",
    "        # create a co that for each ROI (i,e row), calcutes the meanc\n",
    "        df_temp = pd.DataFrame({'ROI' : df_treatment.index})\n",
    "        df_temp['Mean Treatment'] = df_treatment.mean(axis=1).values\n",
    "        df_temp['Mean Baseline'] = df_baseline.mean(axis=1).values\n",
    "\n",
    "        #print(df_temp)\n",
    "\n",
    "        # Calculate the logFC\n",
    "            # Go thorugh each row(ie. ROI) of df_temp and caluclte logFC\n",
    "        logFC = []\n",
    "        for _, row in df_temp.iterrows():\n",
    "\n",
    "            logFC_roi = 0\n",
    "            mean_baseline = row[\"Mean Baseline\"]\n",
    "            mean_treatment = row[\"Mean Treatment\"]\n",
    "\n",
    "            if mean_baseline == 0 and mean_treatment == 0: # Not important case\n",
    "                logFC_roi = 0\n",
    "            elif mean_baseline == 0 and mean_treatment != 0:\n",
    "                logFC_roi = logFC_bound\n",
    "            elif mean_baseline != 0 and mean_treatment == 0:\n",
    "                logFC_roi = -logFC_bound\n",
    "            elif mean_baseline != 0 and mean_treatment != 0: # Normal case\n",
    "                logFC_roi = np.log2(mean_treatment / mean_baseline)\n",
    "\n",
    "            logFC.append(logFC_roi)\n",
    "\n",
    "        # Add col    \n",
    "        df_temp[\"LogFC\"] = logFC\n",
    "\n",
    "        # Sort values\n",
    "        df_temp = df_temp.sort_values(by=\"LogFC\", ascending=False)\n",
    "\n",
    "        #print(df_temp)\n",
    "\n",
    "        # Take the biggest and smallest in absolute values ROI with logFC\n",
    "        # Also take the ones that have been bounded\n",
    "\n",
    "        # Filter for extreme ROIs based on the logFC bound\n",
    "        extreme_rois = df_temp[~((df_temp[\"LogFC\"] < logFC_bound) & (df_temp[\"LogFC\"] > -logFC_bound))][\"ROI\"].to_list()\n",
    "            # NB .index is the names of the ROI column\n",
    "    \n",
    "        # Take only NORMAL ROIs (within the bounds)\n",
    "        t = df_temp[(df_temp[\"LogFC\"] < logFC_bound) & (df_temp[\"LogFC\"] > -logFC_bound)]\n",
    "\n",
    "        # Get top and bottom NORMAL ROIs\n",
    "        top_rois = t.head(n_roi_displayed)[\"ROI\"].to_list() # Take the biggest\n",
    "        bottom_rois = t.tail(n_roi_displayed)[\"ROI\"].to_list() # Take the smallest\n",
    "\n",
    "        # Filter the original DataFrame to include top, bottom, and extreme ROIs\n",
    "        t = df_temp[\n",
    "            df_temp[\"ROI\"].isin(top_rois) | \n",
    "            df_temp[\"ROI\"].isin(bottom_rois) | \n",
    "            df_temp[\"ROI\"].isin(extreme_rois)\n",
    "        ]\n",
    "\n",
    "        #print(t)\n",
    "\n",
    "        t = t.sort_values(by = \"LogFC\", ascending=False)\n",
    "\n",
    "        # Create the bar plot\n",
    "        fig, ax = plt.subplots(figsize=(20, 10 ))\n",
    "        bars = plt.bar(t[\"ROI\"], t[\"LogFC\"])\n",
    "\n",
    "        ax.set_xlabel('ROI')\n",
    "        ax.set_ylabel(key)\n",
    "        ax.set_title('Most extreme changed in LogFC')\n",
    "        ax.set_xticks(range(len(t.index)))\n",
    "        ax.set_xticklabels(t[\"ROI\"], rotation=45, ha='right')\n",
    "        ax.set_ylim(bottom = -10, top = 10)\n",
    "        #plt.show()\n",
    "\n",
    "        # Create reuslt folder\n",
    "        injection_folder = search_injection_folder(dir_project, region) # Search the dolfer of the injection\n",
    "        result_folder = os.path.join(injection_folder, \"Results\") \n",
    "        os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "        #Save fig\n",
    "        save_path = os.path.join(result_folder, f\"logFC_1weeks_uninjured_{region}_{n_roi_displayed}.pdf\")\n",
    "        #fig.savefig(save_path)\n",
    "        print(f\"\\tSaved {key} for region {region}\")\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainrender-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
