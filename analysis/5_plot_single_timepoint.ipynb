{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Single TimePoint for a specific Region on Injection\n",
    "\n",
    "This scripts creates the followinf images:\n",
    "- barplot with the most mean dense region of all mice of a specific timepoint and region injection\n",
    "- 2D HeatMaps of mean density ROI of all mice of a specific timepoint and region injection\n",
    "\n",
    "**ATTENTION**: \n",
    "- as the script uses code taken from `4_2D_heatmpas_single_brain.ipynb`, check it to see the dependencies to install and the differenrt parameters to choose from.\n",
    "- it is decided to plot and analyze all the ROIs, not just the leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import brainglobe_heatmap as bgh #Please use a VE where brainrender is installed\n",
    "from brainglobe_atlasapi import BrainGlobeAtlas\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Inputs\n",
    "\n",
    "# Dir of the project (if script is run on batch mode, i.e. for all brains of the project)\n",
    "dir_project = \"/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset\"\n",
    "\n",
    "# Csv file with all the brains data\n",
    "csv_file = \"/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/Results/all_brains.csv\"\n",
    "\n",
    "# number of the ROI to display in a plot\n",
    "n_roi_displayed = 10 \n",
    "\n",
    "## Imputs for Barplots\n",
    "\n",
    "# List of region to injection to invesigate (one for each folder in the porject)\n",
    "region_injections = [\"DR\", \"STN\", \"PARN\", \"IF\", \"GPi\", \"GPe\", \"CU\", \"BST\"]\n",
    "# List of Timepoints to investigate\n",
    "timepoints = [\"Uninjured\", \"1 weeks\", \"8 weeks\"]\n",
    "\n",
    "## Imputs for HeatMaps\n",
    "\n",
    "# Choose how many slices show, initial and final cuts\n",
    "start_cut = 0 #from olfacotry bulb\n",
    "end_cut = 13000 #to myelenchephalon\n",
    "step = 5000\n",
    "\n",
    "# Select an atlas\n",
    "atlas_name = \"allen_mouse_50um\"\n",
    "bg_atlas = BrainGlobeAtlas(atlas_name, check_latest=False)\n",
    "\n",
    "# Show only leaves nodes\n",
    "only_leaves = False\n",
    "    #ATTENTION: if you show all the ROIs it is importnat the irder that they have in the df\n",
    "        # Indeed if the \"root\" is at the end, i will see only it because it is put on top of everything\n",
    "\n",
    "# fps of the video\n",
    "fps = 5\n",
    "\n",
    "# Choose the fraction of the colormap to start from (0.0 = start, 1.0 = end)\n",
    "start_fraction = 0.1  # Adjust this value as needed\n",
    "\n",
    "# Show or not colorbar in final images\n",
    "show_colorbar = False\n",
    "            #ATTENTION: ratios\n",
    "                # if colormap is there: left_ratio=0.493,right_ratio=0.507\n",
    "                # if colormap is NOT there: left_ratio=0.511,right_ratio=0.489\n",
    "            #ATTENTION: if the ratios are not correct, use the box \"To see where to cut\" to find the best ratios\n",
    "if show_colorbar == True:\n",
    "    left_ratio=0.493\n",
    "    right_ratio=0.507\n",
    "else:\n",
    "    left_ratio=0.511\n",
    "    right_ratio=0.489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_merge_png_images(image_path_left, image_path_right, output_path, left_ratio=0.493, right_ratio=0.507):\n",
    "    \"\"\"\n",
    "    Splits and merges two PNG images with the specified ratio for each side.\n",
    "\n",
    "    :param image_path1: Path to the left image.\n",
    "    :param image_path2: Path to the right image.\n",
    "    :param output_path: Path to save the combined image.\n",
    "    :param left_ratio: Ratio of the width to take from the left image.\n",
    "    :param right_ratio: Ratio of the width to take from the right image.\n",
    "    \"\"\"\n",
    "    # Load PNG images\n",
    "    img1 = Image.open(image_path_left)\n",
    "    img2 = Image.open(image_path_right)\n",
    "\n",
    "    # Ensure images have the same height\n",
    "    if img1.size[1] != img2.size[1]:\n",
    "        raise ValueError(\"Images must have the same height.\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    width1, height1 = img1.size\n",
    "    width2, height2 = img2.size\n",
    "\n",
    "    # Calculate cropping dimensions based on the provided ratios\n",
    "    left_crop_width = int(width1 * left_ratio)\n",
    "    right_crop_width = int(width2 * right_ratio)\n",
    "\n",
    "    # Crop each image according to the calculated dimensions\n",
    "    left_half_img1 = img1.crop((0, 0, left_crop_width, height1))\n",
    "    right_half_img2 = img2.crop((width2 - right_crop_width, 0, width2, height2))\n",
    "\n",
    "    # Save the intermediate halves --> TEST WHERE TO CUT!!!\n",
    "    #left_half_img1.save('left_half.png')\n",
    "    #right_half_img2.save('right_half.png')\n",
    "\n",
    "    # Create a new image with combined width\n",
    "    new_width = left_half_img1.width + right_half_img2.width\n",
    "    new_image = Image.new('RGB', (new_width, height1))\n",
    "\n",
    "    # Paste halves into the new image\n",
    "    new_image.paste(left_half_img1, (0, 0))\n",
    "    new_image.paste(right_half_img2, (left_half_img1.width, 0))\n",
    "\n",
    "    # Save the combined image\n",
    "    print(f\"Saving merged heatmap {output_path}\")\n",
    "    new_image.save(output_path)\n",
    "\n",
    "def extract_number(filename):\n",
    "    \"\"\"\n",
    "    Extract the number from the filename.\n",
    "    Assumes filename is in the format 'number.png'.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def create_custom_cmap(start_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Create a custom colormap starting from a specific fraction of the Reds colormap.\n",
    "    \n",
    "    Parameters:\n",
    "    start_fraction (float): Fraction of the Reds colormap to start from (0.0 to 1.0).\n",
    "    \n",
    "    Returns:\n",
    "    LinearSegmentedColormap: A custom colormap starting from the specified fraction.\n",
    "    \"\"\"\n",
    "    # Ensure the starting fraction is within the range [0, 1]\n",
    "    start_fraction = np.clip(start_fraction, 0, 1)\n",
    "    \n",
    "    # Get the 'Reds' colormap\n",
    "    reds = plt.get_cmap('Reds')\n",
    "\n",
    "    # Extract the colormap data\n",
    "    n_colors = reds.N\n",
    "    colors = reds(np.linspace(0, 1, n_colors))\n",
    "\n",
    "    # Calculate the index to start from\n",
    "    start_index = int(start_fraction * (n_colors - 1))\n",
    "    \n",
    "    # Create the custom colormap starting from the chosen fraction\n",
    "    custom_colors = colors[start_index:]\n",
    "    custom_cmap = mcolors.LinearSegmentedColormap.from_list('custom_reds', custom_colors)\n",
    "    \n",
    "    return custom_cmap\n",
    "\n",
    "def data_summary(data, varname, groupnames):\n",
    "    \"\"\"\n",
    "    Function to calculate the mean and standard error for each group, preserving the original order.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A pandas DataFrame containing the data.\n",
    "    - varname: The name of the column containing the variable to be summarized (string).\n",
    "    - groupnames: A list of column names to be used as grouping variables (list of strings).\n",
    "\n",
    "    Returns:\n",
    "    - data_sum: A pandas DataFrame with mean and standard error for each group, preserving the original order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add an index column to preserve the original order\n",
    "    data['_order'] = range(len(data))\n",
    "    \n",
    "    # Group the data by the specified group names\n",
    "    grouped = data.groupby(groupnames)\n",
    "    \n",
    "    # Calculate the mean and standard error for the specified variable\n",
    "    data_sum = grouped[varname].agg(\n",
    "        mean='mean', \n",
    "        std='std', \n",
    "        count='count'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate standard error\n",
    "    data_sum['sem'] = data_sum['std'] / np.sqrt(data_sum['count'])\n",
    "    \n",
    "    # Merge the summary with the original data to preserve the order\n",
    "    data_sum = pd.merge(data[groupnames + ['_order']], data_sum, on=groupnames).sort_values('_order')\n",
    "\n",
    "    # Check for duplicates in the summary DataFrame\n",
    "    if data_sum.duplicated(subset=groupnames).any():\n",
    "        #print(\"Warning: Duplicates found in the summarized data!\")\n",
    "        # Drop duplicates, keeping the first occurrence\n",
    "        data_sum = data_sum.drop_duplicates(subset=groupnames)\n",
    "    \n",
    "    # Sort the summary DataFrame based on the preserved order from the original data\n",
    "    data_sum['_order'] = data.groupby(groupnames)['_order'].first().values\n",
    "    data_sum = data_sum.sort_values('_order')\n",
    "    \n",
    "    # Drop the temporary _order column\n",
    "    data_sum = data_sum.drop(columns=['_order'])\n",
    "    \n",
    "    # Rename the mean and sem columns\n",
    "    data_sum = data_sum.rename(columns={'mean': varname + '_mean', 'sem': varname + '_sem', 'std': varname + '_std'})\n",
    "    \n",
    "    # Drop the 'std' and 'count' columns, as they are not needed\n",
    "    #data_sum = data_sum.drop(columns=['std', 'count'])\n",
    "    \n",
    "    return data_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv with all brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots Most Dense ROI of a TimePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BST Uninjured\n",
      "\tATTENTION: No data for BST Uninjured\n",
      "Processing CU Uninjured\n",
      "\tATTENTION: No data for CU Uninjured\n",
      "Processing DR 8 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing DR Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing DR 1 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe 8 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe 1 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPi Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing IF Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing PARN Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing STN Uninjured\n",
      "\tSuccess in saving plot.\n"
     ]
    }
   ],
   "source": [
    "# Loop through the folder contents\n",
    "for dir_inj in os.scandir(dir_project):\n",
    "\n",
    "    # If the file is not a folder, exit\n",
    "    if not dir_inj.is_dir():\n",
    "        continue\n",
    "    # If the folder is not an injetion folder, exit\n",
    "    if not os.path.basename(dir_inj.path) in region_injections:\n",
    "        continue\n",
    "\n",
    "    # Save injection_side name\n",
    "    injection_region = os.path.basename(dir_inj.path)\n",
    "\n",
    "    for dir_timepoint in os.scandir(dir_inj):\n",
    "\n",
    "        # If the file is not a folder, exit\n",
    "        if not dir_timepoint.is_dir():\n",
    "            continue\n",
    "        # If the folder is not an injetion folder, exit\n",
    "        if not os.path.basename(dir_timepoint.path) in timepoints:\n",
    "            continue\n",
    "\n",
    "        # Create Results folder if not yet present\n",
    "        dir_results = dir_timepoint.path + \"/Results\"\n",
    "        os.makedirs(dir_results, exist_ok=True)\n",
    "\n",
    "        # Save timepoint\n",
    "        timepoint = os.path.basename(dir_timepoint.path)\n",
    "\n",
    "        print(f\"Processing {injection_region} {timepoint}\")\n",
    "\n",
    "        # Select only mice with specifi injection region\n",
    "        df_temp = df_all[df_all[\"Region Injection\"] == injection_region]\n",
    "        # Select only mice with speicific timepoint\n",
    "        df_temp = df_temp[df_temp[\"TimePoint\"] == timepoint]\n",
    "\n",
    "        # In case the df is empty\n",
    "        if df_temp.shape[0] == 0:\n",
    "            print(f\"\\tATTENTION: No data for {injection_region} {timepoint}\")\n",
    "            continue\n",
    "\n",
    "        # Step 1: Calculate the mean cell density for each ROI\n",
    "        mean_cell_density = df_temp.groupby('ROI')['Cell Density'].mean().reset_index()\n",
    "        mean_cell_density.columns = ['ROI', 'Mean Cell Density']\n",
    "\n",
    "        # Step 2: Sort ROIs by mean cell density and select the top N ROIs\n",
    "        top_roi = mean_cell_density.sort_values(by='Mean Cell Density', ascending=False)\n",
    "        top_roi = top_roi.head(n_roi_displayed)\n",
    "        top_rois = top_roi['ROI'].tolist()\n",
    "\n",
    "        # Step 3: Filter the data for the top N ROIs\n",
    "        df_top_rois = df_temp[df_temp['ROI'].isin(top_rois)]\n",
    "\n",
    "        # Step 4: Create the plot for the top N ROIs\n",
    "        fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "        # Plot mean and standard deviation for each top ROI\n",
    "        for roi in top_rois:\n",
    "\n",
    "            # Filter data for the current ROI\n",
    "            df_roi = df_top_rois[df_top_rois['ROI'] == roi]\n",
    "\n",
    "            #NB EACH ROW IS A SAMPLE --> useful for calculating the sme\n",
    "\n",
    "            # Calculate mean and standard error\n",
    "            mean_value = df_roi['Cell Density'].mean()\n",
    "            std_error = df_roi['Cell Density'].std() / np.sqrt(len(df_roi))\n",
    "            std_value = df_roi['Cell Density'].std()\n",
    "            \n",
    "            # Plot the bar for the mean with error bar for std\n",
    "            ax.bar(roi, mean_value, yerr=std_error, capsize=5, label=f'{roi} (mean ± sme)', color = 'lightblue', alpha=0.7)\n",
    "\n",
    "            # Add the jittered swarm plot\n",
    "            sns.swarmplot(data=df_roi, x='ROI', y='Cell Density', color='black', alpha=0.6)\n",
    "\n",
    "        # Add Full name of ROIs\n",
    "        textstr = df_top_rois[[\"Region\", \"Name\"]].drop_duplicates(subset=\"Region\").to_string(index=False) # Creates text to put inside, i.e. the 2 cols of the df\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5) # Properties text\n",
    "        ax.text(0.7, 1, textstr, transform=ax.transAxes, fontsize=8, verticalalignment='top', multialignment=\"left\", bbox=props)\n",
    "\n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('ROI')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title(f'Mean and SME for the Top {n_roi_displayed} ROIs with Highest Mean Cell Density')\n",
    "        #ax.legend(title='ROIs')\n",
    "        ax.legend().set_visible(False)\n",
    "        plt.xticks(rotation=45)\n",
    "        #ax.tight_layout()\n",
    "\n",
    "        ####\n",
    "        #plt.show()\n",
    "        #raise StopExecution\n",
    "        ####\n",
    "\n",
    "        fig.savefig(dir_results + \"/barplots_most_dense_ROI.pdf\")\n",
    "\n",
    "        print(f\"\\tSuccess in saving plot.\")\n",
    "\n",
    "        #######\n",
    "\n",
    "        # Save memory\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots Most Dense ROI of a TimePoint with Contralateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BST Uninjured\n",
      "\tATTENTION: No data for BST Uninjured\n",
      "Processing CU Uninjured\n",
      "\tATTENTION: No data for CU Uninjured\n",
      "Processing DR 8 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing DR Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing DR 1 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe 8 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing GPe 1 weeks\n",
      "\tSuccess in saving plot.\n",
      "Processing GPi Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing IF Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing PARN Uninjured\n",
      "\tSuccess in saving plot.\n",
      "Processing STN Uninjured\n",
      "\tSuccess in saving plot.\n"
     ]
    }
   ],
   "source": [
    "# Loop through the folder contents\n",
    "for dir_inj in os.scandir(dir_project):\n",
    "\n",
    "    # If the file is not a folder, exit\n",
    "    if not dir_inj.is_dir():\n",
    "        continue\n",
    "    # If the folder is not an injetion folder, exit\n",
    "    if not os.path.basename(dir_inj.path) in region_injections:\n",
    "        continue\n",
    "\n",
    "    # Save injection_side name\n",
    "    injection_region = os.path.basename(dir_inj.path)\n",
    "\n",
    "    for dir_timepoint in os.scandir(dir_inj):\n",
    "\n",
    "        # If the file is not a folder, exit\n",
    "        if not dir_timepoint.is_dir():\n",
    "            continue\n",
    "        # If the folder is not a timepoint folder, exit\n",
    "        if not os.path.basename(dir_timepoint.path) in timepoints:\n",
    "            continue\n",
    "\n",
    "        # Create Results folder if not yet present\n",
    "        dir_results = dir_timepoint.path + \"/Results\"\n",
    "        os.makedirs(dir_results, exist_ok=True)\n",
    "\n",
    "        # Save timepoint\n",
    "        timepoint = os.path.basename(dir_timepoint.path)\n",
    "\n",
    "        print(f\"Processing {injection_region} {timepoint}\")\n",
    "\n",
    "        # Select only mice with specifi injection region\n",
    "        df_temp = df_all[df_all[\"Region Injection\"] == injection_region]\n",
    "        # Select only mice with speicific timepoint\n",
    "        df_temp = df_temp[df_temp[\"TimePoint\"] == timepoint]\n",
    "\n",
    "        # In case the df is empty\n",
    "        if df_temp.shape[0] == 0:\n",
    "            print(f\"\\tATTENTION: No data for {injection_region} {timepoint}\")\n",
    "            continue\n",
    "\n",
    "        # Step 1: Calculate the mean cell density for each ROI\n",
    "        mean_cell_density = data_summary(df_temp, varname=\"Cell Density\", groupnames=[\"TimePoint\", \"Region Injection\", \"ROI\", \"Region\", \"Side\", \"Name\"])\n",
    "            #all reduntant to group by them, but in this way trhe coluns are mantaind\n",
    "\n",
    "        #print(mean_cell_density)\n",
    "\n",
    "        # Step 2: Sort ROIs by mean cell density and select the top N ROIs\n",
    "        df_top_roi = mean_cell_density.sort_values(by='Cell Density_mean', ascending=False).head(n_roi_displayed)\n",
    "        name_max_regions = df_top_roi['ROI'].tolist()\n",
    "        values_max_regions = df_top_roi[\"Cell Density_mean\"].to_list()\n",
    "\n",
    "        name_contralateral_regions = []\n",
    "        values_contralateral_regions = []\n",
    "\n",
    "        for idx, row in df_top_roi.iterrows():\n",
    "\n",
    "            #info relative to the max region\n",
    "            region = row['Region']\n",
    "            side = row['Side']\n",
    "            contralateral_side = 'Right' if side == 'Left' else 'Left'\n",
    "            \n",
    "            # Retrieve contralateral density from the map\n",
    "            name_contralateral_regions.append(mean_cell_density[(mean_cell_density[\"Region\"] == region) & (mean_cell_density[\"Side\"] == contralateral_side)][\"ROI\"].values[0])\n",
    "            values_contralateral_regions.append(mean_cell_density[(mean_cell_density[\"Region\"] == region) & (mean_cell_density[\"Side\"] == contralateral_side)][\"Cell Density_mean\"].values[0])\n",
    "\n",
    "        # Print the filtered DataFrame for debugging\n",
    "        #print(df_top_rois)\n",
    "\n",
    "        width = 0.9\n",
    "        ind = np.arange(len(values_max_regions))\n",
    "        fig, ax = plt.subplots(figsize=(20,10))\n",
    "        ax.bar(x=ind, height=values_max_regions, width=width,align='center', label='Max Regions')\n",
    "        ax.bar(x=ind, height=values_contralateral_regions, width=width/3,  align='center', label='Contralateral Regions')\n",
    "        ax.legend()\n",
    "        plt.xticks(ind, name_max_regions, rotation = 45)\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        # Add Full name of ROIs\n",
    "        textstr = df_top_roi[[\"Region\", \"Name\"]].drop_duplicates(subset=\"Region\").to_string(index=False)\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5) # Properties text\n",
    "        ax.text(0.8, 0.9, textstr, transform=ax.transAxes, fontsize=8, verticalalignment='top', multialignment=\"left\", bbox=props)\n",
    "\n",
    "        ####\n",
    "        #plt.show()\n",
    "        #raise StopExecution\n",
    "        ####\n",
    "\n",
    "        fig.savefig(dir_results + \"/barplots_most_dense_ROI_with_contralateral.pdf\")\n",
    "\n",
    "        print(f\"\\tSuccess in saving plot.\")\n",
    "\n",
    "\n",
    "        #######\n",
    "\n",
    "        # Save memory\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean HeatMaps\n",
    "\n",
    "Please check the script `4_2D_heatmpas_single_brain.ipynb` for a detailed explanation of the following code (dependencies, parameters, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Custum cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 80\u001b[0m\u001b[1;36m0x200\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the custom colormap\n",
    "    #chnage \"start_fraction\" to start the colormap from a higher or lower color\n",
    "custom_cmap = create_custom_cmap(start_fraction=start_fraction)\n",
    "\n",
    "# Test the custom colormap\n",
    "data = np.linspace(0, 1, 100).reshape(1, -1)\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.imshow(data, aspect='auto', cmap=custom_cmap)\n",
    "plt.axis('off')\n",
    "plt.title(f'Custom Reds Colormap Starting from {start_fraction * 100:.0f}%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Heatmaps \n",
    "\n",
    "**Attention**: the following HeatMaps depict the mean density, not the density of a single brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BST 8 weeks\n",
      "Processing BST Uninjured\n",
      "Processing CU 8 weeks\n",
      "Processing CU Uninjured\n",
      "Processing DR 8 weeks\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Porcessing cut number Left-0\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 0.png\n",
      "\n",
      "Porcessing cut number Left-5000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 5000.png\n",
      "\n",
      "Porcessing cut number Left-10000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 10000.png\n",
      "\n",
      "Porcessing cut number Right-0\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 0.png\n",
      "\n",
      "Porcessing cut number Right-5000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 5000.png\n",
      "\n",
      "Porcessing cut number Right-10000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 10000.png\n",
      "\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/8 weeks/Results/2D_heatmaps/Merged/0.png\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/8 weeks/Results/2D_heatmaps/Merged/5000.png\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/8 weeks/Results/2D_heatmaps/Merged/10000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video creation complete at /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/8 weeks/Results/2D_heatmaps/Merged/video_merged_heatmaps.mp4\n",
      "\n",
      "Processing DR Uninjured\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Porcessing cut number Left-0\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 0.png\n",
      "\n",
      "Porcessing cut number Left-5000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 5000.png\n",
      "\n",
      "Porcessing cut number Left-10000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 10000.png\n",
      "\n",
      "Porcessing cut number Right-0\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 0.png\n",
      "\n",
      "Porcessing cut number Right-5000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 5000.png\n",
      "\n",
      "Porcessing cut number Right-10000\n",
      "The region RSPd4 is in the onthology but does not have a corresponding volume in the atlas being used: allen_mouse_50um. Skipping\n",
      "Saved figure: 10000.png\n",
      "\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/Uninjured/Results/2D_heatmaps/Merged/0.png\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/Uninjured/Results/2D_heatmaps/Merged/5000.png\n",
      "Saving merged heatmap /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/Uninjured/Results/2D_heatmaps/Merged/10000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video creation complete at /run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/connectome_analysis/final_dataset/DR/Uninjured/Results/2D_heatmaps/Merged/video_merged_heatmaps.mp4\n",
      "\n",
      "Processing DR 1 weeks\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Processing GPe 8 weeks\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Processing GPe Uninjured\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Processing GPe 1 weeks\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Processing GPi 8 weeks\n",
      "Processing GPi Uninjured\n",
      "Warning: Duplicates found in the summarized data!\n",
      "Processing IF 8 weeks\n",
      "Processing IF Uninjured\n",
      "Processing PARN 8 weeks\n",
      "Processing PARN Uninjured\n",
      "Processing STN 8 weeks\n",
      "Processing STN Uninjured\n"
     ]
    }
   ],
   "source": [
    "# For Debugging: how many brains process\n",
    "brains_to_process = 2\n",
    "    # n --> if you want to proecces a subset\n",
    "    # None --> if you want to process all\n",
    "\n",
    "brain_processed = 0\n",
    "\n",
    "# Loop through the folder contents\n",
    "for dir_inj in os.scandir(dir_project):\n",
    "\n",
    "    # If the file is not a folder, exit\n",
    "    if not dir_inj.is_dir():\n",
    "        continue\n",
    "    # If the folder is not an injetion folder, exit\n",
    "    if not os.path.basename(dir_inj.path) in region_injections:\n",
    "        continue\n",
    "\n",
    "    # Save injection_region name\n",
    "    injection_region = os.path.basename(dir_inj.path)\n",
    "\n",
    "    for dir_timepoint in os.scandir(dir_inj):\n",
    "\n",
    "        # If the file is not a folder, exit\n",
    "        if not dir_timepoint.is_dir():\n",
    "            continue\n",
    "        # If the folder is not an injetion folder, exit\n",
    "        if not os.path.basename(dir_timepoint.path) in timepoints:\n",
    "            continue\n",
    "\n",
    "        # Save timepoint name\n",
    "        timepoint = os.path.basename(dir_timepoint.path)\n",
    "\n",
    "        ##############################################\n",
    "        ### CREATE FOLDERS ###########################\n",
    "        ##############################################\n",
    "\n",
    "        # Create Results folder if not yet present\n",
    "        dir_results = dir_timepoint.path + \"/Results\"\n",
    "        os.makedirs(dir_results, exist_ok=True)\n",
    "\n",
    "        # Make a dir for images (if doesn't yet exist)\n",
    "        dir_images_name = os.path.join(dir_results, \"2D_heatmaps\")\n",
    "        #print(dir_images_name)\n",
    "        os.makedirs(dir_images_name, exist_ok=True)\n",
    "\n",
    "        #Create a folder where to store them\n",
    "        heatmaps_dir_left = os.path.join(dir_images_name, \"Left\")\n",
    "        heatmaps_dir_right = os.path.join(dir_images_name, \"Right\")\n",
    "        heatmaps_dir_merged = os.path.join(dir_images_name,\"Merged\") \n",
    "        os.makedirs(heatmaps_dir_left, exist_ok=True)\n",
    "        os.makedirs(heatmaps_dir_right, exist_ok=True)\n",
    "        os.makedirs(heatmaps_dir_merged, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing {injection_region} {timepoint}\")\n",
    "\n",
    "        ##############################################\n",
    "        ### CREATE DF WITH MEAN VALUES ###############\n",
    "        ##############################################\n",
    "\n",
    "        # Select only mice with specifi injection region\n",
    "        df_temp = df_all[df_all[\"Region Injection\"] == injection_region]\n",
    "        # Select only mice with speicific timepoint\n",
    "        df_temp = df_temp[df_temp[\"TimePoint\"] == timepoint]\n",
    "\n",
    "        # In case the df is empty\n",
    "        if df_temp.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate the mean cell density for each ROI\n",
    "        df = data_summary(df_temp, \"Cell Density\", [\"ROI\", \"Region\", \"Side\", \"IsLeaf\"]) \n",
    "            #ATTENTION:\n",
    "                # no need no group with other varibales, df alredy filtered before\n",
    "                # when we forup the importnat is to use \"ROI\", all the other varibales are coprrelated to ROI so it is like grouping in ther same way\n",
    "        #df_temp.groupby('ROI')['Cell Density'].mean().reset_index()\n",
    "\n",
    "        brain_processed +=1\n",
    "\n",
    "        if brains_to_process != None: #Only if I want ot precess a speififc number of brains\n",
    "            if brain_processed > brains_to_process:\n",
    "                continue\n",
    "\n",
    "        #print(df)\n",
    "\n",
    "        ##############################################\n",
    "        ### OBSERVATIONS #############################\n",
    "        ##############################################\n",
    "\n",
    "        # Attention: The heatmas will show all regions, not a subset of the most dense\n",
    "\n",
    "        ##############################################\n",
    "        ### CREATE HEATMAPS LEFT #####################\n",
    "        ##############################################\n",
    "\n",
    "        side = \"Left\"\n",
    "\n",
    "        df_side = df[df[\"Side\"] == side]  # Take the ROI only from one side\n",
    "\n",
    "        if only_leaves: # To display only the leaves ROIs\n",
    "            df_side = df[df[\"IsLeaf\"] == True]\n",
    "\n",
    "        # Use only the ROI that are present in the atlas\n",
    "        df_side = df_side[df_side['Region'].isin(bg_atlas.lookup_df[\"acronym\"].to_list())]\n",
    "\n",
    "        # Create the dictionary --> NB take the name withounf left or right\n",
    "        # ex: dict{\"CA1\": 10, \"ENT\": 40, ...}\n",
    "        cell_density_data = dict(zip(df_side['Region'], df_side['Cell Density_mean']))\n",
    "\n",
    "        #print(cell_density_data)\n",
    "\n",
    "        # Iterate over cuts range\n",
    "        for cut in range(start_cut, end_cut+1, step): # +1 so I can take alos the last slice\n",
    "\n",
    "            print(f\"Porcessing cut number {side}-{cut}\")\n",
    "            \n",
    "            # Create Heatmap object\n",
    "            f = bgh.Heatmap(\n",
    "                cell_density_data,\n",
    "                position=cut,\n",
    "                orientation=\"frontal\",  # Adjust orientation as needed\n",
    "                title=\"\", #f\"Side: {side} - Slice position: {cut}\",\n",
    "                vmin=0,\n",
    "                vmax=0.01,\n",
    "                cmap=custom_cmap,\n",
    "                atlas_name=atlas_name,\n",
    "                format='2D', \n",
    "                hemisphere=side.lower(), #Attention lower case\n",
    "                label_regions=False\n",
    "            )\n",
    "            \n",
    "            # Save the figure\n",
    "            fig = f.my_plot(show_colorbar=show_colorbar, show_legend=False, xlabel=\"\", ylabel=\"\", hide_axes=True) \n",
    "                # ATTENTION: MY PLOT IS A CUSTUM FUNCTION\n",
    "                    #just go in the file brainrender-env/lib/python3.9/site-packages/brainglobe_heatmap/heatmaps.py\n",
    "                    #create a new fucntion my_plot that copies the function plot()\n",
    "                    #and comment out the plt.show() at the end\n",
    "            fig_path = os.path.join(dir_images_name, side, f'{cut}.png')\n",
    "            fig.savefig(fig_path, dpi=100)\n",
    "            print(f\"Saved figure: {cut}.png\\n\")\n",
    "            plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "        \n",
    "        ##############################################\n",
    "        ### CREATE HEATMAPS RIGHT #####################\n",
    "        ##############################################\n",
    "\n",
    "        # Attention: Show all regions, not a subset of the most dense\n",
    "\n",
    "        side = \"Right\"\n",
    "\n",
    "        df_side = df[df[\"Side\"] == side]  # Take the ROI only from one side\n",
    "\n",
    "        if only_leaves: # To display only the leaves ROIs\n",
    "            df_side = df[df[\"IsLeaf\"] == True]\n",
    "\n",
    "        # Use only the ROI that are present in the atlas\n",
    "        df_side = df_side[df_side['Region'].isin(bg_atlas.lookup_df[\"acronym\"].to_list())]\n",
    "\n",
    "        # Create the dictionary --> NB take the name withounf left or right\n",
    "        # ex: dict{\"CA1\": 10, \"ENT\": 40, ...}\n",
    "        cell_density_data = dict(zip(df_side['Region'], df_side['Cell Density_mean']))\n",
    "\n",
    "        #print(cell_density_data)\n",
    "\n",
    "        # Iterate over cuts range\n",
    "        for cut in range(start_cut, end_cut+1, step): # +1 so I can take alos the last slice\n",
    "\n",
    "            print(f\"Porcessing cut number {side}-{cut}\")\n",
    "            \n",
    "            # Create Heatmap object\n",
    "            f = bgh.Heatmap(\n",
    "                cell_density_data,\n",
    "                position=cut,\n",
    "                orientation=\"frontal\",  # Adjust orientation as needed\n",
    "                title=\"\", #f\"Side: {side} - Slice position: {cut}\",\n",
    "                vmin=0,\n",
    "                vmax=0.01,\n",
    "                cmap=custom_cmap,\n",
    "                atlas_name=atlas_name,\n",
    "                format='2D', \n",
    "                hemisphere=side.lower(), #Attention lower case\n",
    "                label_regions=False\n",
    "            )\n",
    "            \n",
    "            # Save the figure\n",
    "            fig = f.my_plot(show_colorbar=show_colorbar, show_legend=False,xlabel=\"\", ylabel=\"\", hide_axes=True) \n",
    "                # ATTENTION: MY PLOT IS A CUSTUM FUNCTION\n",
    "                    #just go in the file brainrender-env/lib/python3.9/site-packages/brainglobe_heatmap/heatmaps.py\n",
    "                    #create a new fucntion my_plot that copies the function plot()\n",
    "                    #and comment out the plt.show() at the end\n",
    "            fig_path = os.path.join(dir_images_name, side, f'{cut}.png')\n",
    "            fig.savefig(fig_path, dpi=100)\n",
    "            print(f\"Saved figure: {cut}.png\\n\")\n",
    "            plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ### MERGE IMAGES #############################\n",
    "        ##############################################\n",
    "        \n",
    "        for root, dirs, files in os.walk(heatmaps_dir_left):\n",
    "            for file in files:\n",
    "                file_path_left = os.path.join(heatmaps_dir_left, file) #path fo the file\n",
    "                file_path_right = os.path.join(heatmaps_dir_right, file)\n",
    "                file_path_merged = os.path.join(heatmaps_dir_merged, file)\n",
    "                split_and_merge_png_images(image_path_left=file_path_right, #ATTENTION, are inverted\n",
    "                                            image_path_right=file_path_left,  \n",
    "                                            output_path=file_path_merged, \n",
    "                                            left_ratio=left_ratio,right_ratio=right_ratio)\n",
    "                \n",
    "                #ATTENTION: ratios\n",
    "                    # if colormap is there: left_ratio=0.493,right_ratio=0.507\n",
    "                    # if colormap is NOT there: left_ratio=0.511,right_ratio=0.489\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ### VIDEO ####################################\n",
    "        ##############################################\n",
    "\n",
    "        # Path of the video to save\n",
    "        video_path = heatmaps_dir_merged + '/video_merged_heatmaps.mp4'\n",
    "\n",
    "        # Get the list of image files in the folder\n",
    "        images = [img for img in os.listdir(heatmaps_dir_merged) if img.endswith(\".png\")]\n",
    "        images.sort(key=extract_number)  # important to sort in the correct way\n",
    "\n",
    "        # Read the first image to get the width and height\n",
    "        first_image = cv2.imread(os.path.join(heatmaps_dir_merged, images[0]))\n",
    "        height, width, layers = first_image.shape\n",
    "\n",
    "        # Define the codec and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can use 'MJPG' or 'MP4V' if preferred\n",
    "        video = cv2.VideoWriter(video_path, fourcc, fps, (width, height))  # 1 is the frame rate\n",
    "\n",
    "        for image in images:\n",
    "            image_path = os.path.join(heatmaps_dir_merged, image)\n",
    "            img = cv2.imread(image_path)\n",
    "            video.write(img)  # Write each frame to the video\n",
    "\n",
    "        # Release the video writer object\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(f\"\\nVideo creation complete at {video_path}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return []\n",
    "\n",
    "raise StopExecution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainrender-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
