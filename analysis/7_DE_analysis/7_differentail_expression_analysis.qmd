---
title: "differentail_expression_analisys"
format: html
editor: visual
---

Run DE analysis for a specific injection region. The default test used is **edgeR** with **Likelihood Ratio Test (LRT)**, along with **Benjamini-Hochberg FDR control** for p-value adjustment. No normalization is performed prior to GLM fitting.

**ATTENTION**:\
- This analysis focuses on "Synapses" counts.\
- If normalization is tagged the RLE method is choosen for normlaization - The significance of a region is determined using the adjusted p-value (p-value-adj).\
- The analysis is performed only on the leaves (terminal nodes).

**Customizing Your Analysis**:\
By modifying the script, you can:\
- Adjust the p-value using different methods.\
- Choose to normalize the data or not, and if so, select from various normalization methods.\
- Use the `differential_activity` function to perform alternative tests.\
- Instead of using just leaves, you could try to use other hierarchical level.

# Libraries

```{r}
library(edgeR)
library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(tibble)
library(forcats)
library(gridExtra)

```

# Differential_activity.R Function

```{r}
#' Run differential activation (based on bulk RNA-seq analysis)
#' 
#' Run differential activation (based on bulk RNA-seq analysis)
#' 
#' @param input a count matrix to be analyzed, with features (regions) in rows
#'   and brains in columns. 
#' @param meta the accompanying meta data whereby the rownames match the column
#'   names of \code{input}.
#' @param replicate_col the vector in \code{meta} containing the replicate 
#'   information. Defaults to \code{replicate}.
#' @param label_col the vector in \code{meta} containing the experimental
#'   label. Defaults to \code{label}. 
#' @param min_features the minimum number of expressing brains
#'   for a region to retain it. Defaults to \code{0}.
#' @param de_method the specific differential expression testing method to use.
#'   Defaults to edgeR.
#' @param de_type the specific parameter of the differential expression testing
#'   method. Defaults to LRT for edgeR, LRT for DESeq2, and trend for limma.
#' @return a data frame containing differential expression results.
#'  
#' @importFrom magrittr %<>%
#' @importFrom tibble rownames_to_column
#' @importFrom dplyr %>% mutate n_distinct
#' @importFrom edgeR DGEList calcNormFactors estimateDisp glmQLFit glmQLFTest
#'   glmFit glmLRT topTags cpm
#' @importFrom DESeq2 DESeqDataSetFromMatrix DESeq results
#' @importFrom limma voom lmFit eBayes topTable
#' @importFrom purrr map 
#' @importFrom stats model.matrix
#' @importFrom methods new
#' 
#' @export
differential_activity = function(input, 
                         meta = NULL, 
                         replicate_col = 'replicate',
                         label_col = 'label',
                         min_features = 0,
                         de_family = 'pseudobulk',
                         de_method = 'edgeR',
                         de_type = 'LRT',
                         normalise = TRUE) {
  # check args
  if (de_method == 'limma') {
    if (de_type != 'voom') {
      # change default type to use
      de_type = 'trend'  
    }
  }
  
  # define a targets df
  targets = meta

  ## optionally, carry over factor levels from entire dataset
  if (is.factor(meta$label)) {
    targets$label %<>% factor(levels = levels(meta$label))
  }
  if (n_distinct(targets$label) > 2)
    return(NULL)
  # create design
  #design = model.matrix(~ label_col, data = targets)
  design = model.matrix(~ label, data = targets)
  
  DA = switch(de_method,
              edgeR = {
                tryCatch({
                  if(normalise == TRUE){
                    y = DGEList(counts = input, group = targets$label) %>%
                      #calcNormFactors(method = 'TMM') %>
                      calcNormFactors(method = 'RLE') %>%
                      estimateDisp(design)
                  } else{
                    y = DGEList(counts = input, group = targets$label) %>%
                      estimateDisp(design)
                  }
                  test = switch(de_type,
                                QLF = {
                                  fit = glmQLFit(y, design)
                                  test = glmQLFTest(fit, coef = -1)
                                },
                                LRT = {
                                  fit = glmFit(y, design = design)
                                  test = glmLRT(fit)
                                })
                  res = topTags(test, n = Inf, adjust.method = "BH") %>%
                    as.data.frame() %>%
                    rownames_to_column('region') %>%
                    # flag metrics in results
                    mutate(de_family = 'pseudobulk',
                           de_method = de_method,
                           de_type = de_type)
                }, error = function(e) {
                  message(e)
                  data.frame()
                })
              },
              DESeq2 = {
                tryCatch({
                  dds = DESeqDataSetFromMatrix(countData = input,
                                               colData = targets,
                                               design = ~ label)
                  dds = switch(de_type,
                               Wald = {
                                 dds = try(DESeq(dds,
                                                 test = 'Wald',
                                                 fitType = 'parametric',
                                                 sfType = 'poscounts',
                                                 betaPrior = F))
                               },
                               LRT = {
                                 dds = try(DESeq(dds,
                                                 test = 'LRT',
                                                 reduced = ~ 1,
                                                 fitType = 'parametric',
                                                 sfType = 'poscounts',
                                                 betaPrior = F))
                               }
                  )
                  res = results(dds)
                  # write
                  res = as.data.frame(res) %>%
                    mutate(region = rownames(input)) %>%
                    # flag metrics in results
                    mutate(de_family = 'pseudobulk',
                           de_method = de_method,
                           de_type = de_type)
                }, error = function(e) {
                  message(e)
                  data.frame()
                })
              },
              limma = {
                tryCatch({
                  x = switch(de_type,
                             trend = {
                               trend_bool = T
                               dge = DGEList(as.matrix(input), group = targets$label)
                               dge = calcNormFactors(dge)
                               x = new("EList")
                               x$E = cpm(dge, log = TRUE, prior.count = 3)
                               x
                             },
                             voom = {
                               counts = all(as.matrix(input) %% 1 == 0)
                               if (counts) {
                                 trend_bool = F
                                 x = voom(as.matrix(input), design)
                                 x
                               }
                             })
                  # get fit
                  fit = lmFit(x, design) %>%
                    eBayes(trend = trend_bool, robust = trend_bool)
                  # format the results
                  res = fit %>%
                    # extract all coefs except intercept
                    topTable(number = Inf, coef = -1) %>%
                    rownames_to_column('region') %>%
                    # flag metrics in results
                    mutate(
                      de_family = 'pseudobulk',
                      de_method = de_method,
                      de_type = de_type)
                }, error = function(e) {
                  message(e)
                  data.frame()
                })
              }
  )
  
  # clean up the output
  suppressWarnings(
    colnames(DA) %<>%
      fct_recode('p_val' = 'p.value',  ## DESeq2
                 'p_val' = 'pvalue',  ## DESeq2
                 'p_val' = 'p.value',  ## t/wilcox
                 'p_val' = 'P.Value',  ## limma
                 'p_val' = 'PValue'  , ## edgeR
                 'p_val_adj' = 'padj', ## DESeq2/t/wilcox
                 'p_val_adj' = 'adj.P.Val',      ## limma
                 'p_val_adj' = 'FDR',            ## edgeER
                 'avg_logFC' = 'log2FoldChange', ## DESEeq2
                 'avg_logFC' = 'logFC' ## limma/edgeR
      )
  ) %>%
    as.character()
  
  DA %<>%
    # calculate adjusted p values
    mutate(p_val_adj = p.adjust(p_val, method = 'BH')) %>%
    # make sure region is a character not a factor
    mutate(region = as.character(region)) %>%
    dplyr::select(region,
                  avg_logFC,
                  p_val,
                  p_val_adj,
                  de_family,
                  de_method,
                  de_type
    ) %>%
    ungroup() %>%
    arrange(p_val_adj)
  
}
```

# Mandatory Inputs

```{r}
### TO CHANGE EVERY TIME

# Select one region of Injection
region_injection = "DR"
# Save folder
save_path = "/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/DR/Results"
    # EX."/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/DR/Results"


### TO CHNAGE AT OCCURENCE

# Contrast to compare
contrasts = list(c("1 weeks", "8 weeks"), c("Uninjured", "1 weeks"), c("Uninjured", "8 weeks"))
# max p-avleu over with a region is no more signification (referred to adjusted p-value)
p_value = 0.05
# How many most differt ROI display
n_roi_diplayed = 20
# Load data
df_all = read.csv("/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/Results/all_brains.csv")
df_meta_all = read.csv("/run/user/1000/gvfs/smb-share:server=upcourtinenas,share=cervical/CERVICAL_ID/Connectome_analysis/Final_dataset/Results/all_brains_meta.csv")

```

# Create Folders

```{r}
lineplots_folder = file.path(save_path, "LinePlots")
disconnection_folder = file.path(lineplots_folder, "Disconnetion")
newconnections_folder = file.path(lineplots_folder, "NewConnections")
recoverydown_folder = file.path(lineplots_folder, "RecoveryDown")
recoveryup_folder = file.path(lineplots_folder, "RecoveryUp")

# Create the directories if they do not exist
if (!dir.exists(lineplots_folder)) {
  dir.create(lineplots_folder, recursive = TRUE)
}

if (!dir.exists(disconnection_folder)) {
  dir.create(disconnection_folder, recursive = TRUE)
}

if (!dir.exists(newconnections_folder)) {
  dir.create(newconnections_folder, recursive = TRUE)
}

if (!dir.exists(recoverydown_folder)) {
  dir.create(recoverydown_folder, recursive = TRUE)
}

if (!dir.exists(recoveryup_folder)) {
  dir.create(recoveryup_folder, recursive = TRUE)
}
```

# Run DE analysis

```{r}

# big df with all contratss
df_da_all_contrasts = data.frame()

for (contrast in contrasts){
  
  baseline = contrast[1]
  treated = contrast[2]
  
  # Select only relative data
  df = df_all[(df_all$TimePoint %in% contrast) & 
              (df_all$`Region.Injection` == region_injection),]
  
  # Select only leaves ROI
  df = df[df$IsLeaf == "True",]
  
  # Create meta df
  df_meta = df_meta_all[(df_meta_all$TimePoint %in% contrast) & 
                        (df_meta_all$`Region.Injection` == region_injection),]
  df_meta$TimePoint = as.factor(df_meta$TimePoint)
  df_meta = df_meta %>% dplyr::rename(label = TimePoint) # ATTENTION: MUST BE CALLED "LABEL" FOR NEXTY FUNCTION
  df_meta$label <- relevel(df_meta$label, ref = baseline) # ATTENTION: SET THE BALINE CONDTION THAT YOU WANT

  
  # Pivot data (to create a count matrix)
  df <- pivot_wider(df, 
                    id_cols = ROI, 
                    names_from = c(`Brain.ID`, `Region.Injection`, TimePoint), 
                    values_from = `Synapses`)
  
  # create counts
  counts <- as.matrix(df[,-1])  # Assuming the first column is ROI and should be excluded
  rownames(counts) <- df$ROI   # Set gene names as rownames
  colnames(counts) <- df_meta$Brain.ID # Check column names to ensure they match metadata
    
  # Perform the test
  da_df = differential_activity(input = counts, 
                           meta = df_meta, 
                           replicate_col = 'replicate',
                           label_col = 'label',
                           min_features = 0,
                           de_family = 'pseudobulk',
                           de_method = 'edgeR',
                           de_type = 'LRT',
                           normalise = FALSE) # I do not normalize
  
  # Add columns to df
  da_df = da_df %>%
          mutate(baseline = baseline,
                 treated= treated) %>%
          # add the direction!!
          mutate(direction = ifelse(avg_logFC < 0, 
                                    paste0(treated, ' < ', baseline), # ATTENTION: use only "<", to have continutity with future code
                                    paste0(baseline, ' < ', treated)),
                 significant = ifelse(p_val_adj < p_value, "*", "n.s."))
  
    
    print(da_df)
    
    # Add ot the df contrast list
    df_da_all_contrasts = rbind(df_da_all_contrasts, da_df)
    
    
}


# Display the merged data frame
print(df_da_all_contrasts) #1680 ROIs x 2contarts = 5040
```

# Asses Archetypes

```{r}
# Just change name
da = df_da_all_contrasts



## Archetype 1: 1w < UN and 1w < 8w --> RECOVERY UP
## (gradually improving and reaching baseline levels by increasing)
arch_a1 = "RecoveryUp"
a1 = da %>%
  filter(p_val_adj < 0.05) %>%
  filter(direction %in% c("1 weeks < Uninjured", "1 weeks < 8 weeks")) %>% # Take only the rows of these 2 conditions
  # ask which ones have both criteria
  group_by(region) %>% #Create groups based on the ROI
  mutate(count = n()) %>%
  filter(count == 2) %>% #Take only the gouprs(ROI) that have 2 rows --> i.e  regions that meet both criteria
  ungroup() %>%
  mutate(archetype = arch_a1, region_injection = region_injection)

# try looking by rank even if they are not significant
  # do not take into accou tp-value
  #calculates a cumulative rank: regions sorted by their cumulative rank, indicating how well the regions rank overall in terms of their p-values across the specified conditions.
a1_rank = da %>%
  filter(direction %in% c("1 weeks < Uninjured", "1 weeks < 8 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  group_by(direction) %>% # creates 2 grousp (one for each direction, i.e. pair of condtions)
  arrange(p_val_adj) %>%
  mutate(rank = rank(p_val_adj)) %>% # in each group(direction of before), give a point based on rank
  group_by(region) %>%
  mutate(sum_rank = sum(rank)) %>% #sum the 2 rnaks of the 2 directiosn in acumulative rank
  ungroup() %>%
  arrange(sum_rank) %>%
  dplyr::select(region, sum_rank) %>%
  distinct() %>%
  tail(n_roi_diplayed) %>%# Takr the one with biggest ranks
  mutate(archetype = arch_a1, region_injection = region_injection)



## Archetype 2: UN < 1wk and 8w < 1w --> RECOVERY DOWN
## (gradually improving and reaching baseline levels by decreasing)
arch_a2 = "RecoveryDown"
a2 = da %>%
  filter(p_val_adj < 0.05) %>%
  filter(direction %in% c("Uninjured < 1 weeks", "8 weeks < 1 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  ungroup() %>%
  mutate(archetype = arch_a2, region_injection = region_injection)

# try looking by rank even if they are not significant
a2_rank = da %>%
  filter(direction %in% c("Uninjured < 1 weeks", "8 weeks < 1 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  group_by(direction) %>%
  arrange(p_val_adj) %>%
  mutate(rank = rank(p_val_adj)) %>%
  group_by(region) %>%
  mutate(sum_rank = sum(rank)) %>%
  ungroup() %>%
  arrange(sum_rank) %>%
  dplyr::select(region, sum_rank) %>%
  distinct() %>%
  tail(n_roi_diplayed) %>%
  mutate(archetype = arch_a2, region_injection = region_injection)



## Archetype 3: 1w < UN  and 8w < UN--> DISCOENNECTION
## (Lose connections)
arch_a3 = "Disconnection"
a3 = da %>%
  filter(p_val_adj < 0.05) %>%
  filter(direction %in% c("1 weeks < Uninjured", "8 weeks < 1 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  ungroup() %>%
  mutate(archetype = arch_a3, region_injection = region_injection)

# try looking by rank even if they are not significant
a3_rank = da %>%
  filter(direction %in% c("1 weeks < Uninjured", "8 weeks < 1 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  group_by(direction) %>%
  arrange(p_val_adj) %>%
  mutate(rank = rank(p_val_adj)) %>%
  group_by(region) %>%
  mutate(sum_rank = sum(rank)) %>%
  ungroup() %>%
  arrange(sum_rank) %>%
  dplyr::select(region, sum_rank) %>%
  distinct() %>%
  tail(n_roi_diplayed) %>%
  mutate(archetype = arch_a3, region_injection = region_injection)



## Archetype 4: UN < 1w and 1w < 8w --> New Connections
## (region gradually becoming more and more active to compensate 
## for the loss of function)
arch_a4 = "NewConnections"
a4 = da %>%
  filter(p_val_adj < 0.05) %>%
  filter(direction %in% c("Uninjured < 1 weeks", "1 weeks < 8 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  ungroup() %>%
  mutate(archetype = arch_a4, region_injection = region_injection)

# try looking by rank even if they are not significant
a4_rank = da %>%
  filter(direction %in% c("Uninjured < 1 weeks", "1 weeks < 8 weeks")) %>%
  # ask which ones have both criteria
  group_by(region) %>%
  mutate(count = n()) %>%
  filter(count == 2) %>%
  group_by(direction) %>%
  arrange(p_val_adj) %>%
  mutate(rank = rank(p_val_adj)) %>%
  group_by(region) %>%
  mutate(sum_rank = sum(rank)) %>%
  ungroup() %>%
  arrange(sum_rank) %>%
  dplyr::select(region, sum_rank) %>%
  distinct() %>%
  tail(n_roi_diplayed) %>%
  mutate(archetype = arch_a4, region_injection = region_injection)


```

# Save results

```{r}
# Merge all of them together
df_significant = rbind(a1, a2, a3, a4)
df_rank = rbind(a1_rank, a2_rank, a3_rank, a4_rank)

# Save
# save_folder = paste0(save_path, "/DE_analysis_", region_injection)
# if (!file.exists(save_folder)) {
#   dir.create(save_folder)
# }
write.csv(df_significant, paste0(save_path, "/significant_roi_archetypes_", region_injection, ".csv"), row.names = FALSE)
write.csv(df_rank, paste0(save_path, "/rank_roi_archetypes_", region_injection, ".csv"), row.names = FALSE)

```

# Plots

```{r}
#+++++++++++++++++++++++++
# Function to calculate the mean, standard deviation (SD), and standard error (SE)
# for each group and include a column with the list of values used for calculation
#+++++++++++++++++++++++++
# data : a data frame
# varname : the name of a column containing the variable to be summarized
# groupnames : vector of column names to be used as grouping variables
data_summary <- function(data, varname, groupnames) {
  # Function to calculate mean, standard deviation, standard error, and values list
  summary_func <- function(x, col) {
    n <- sum(!is.na(x[[col]]))  # Number of non-missing values
    mean_val <- mean(x[[col]], na.rm = TRUE)  # Mean
    sd_val <- sd(x[[col]], na.rm = TRUE)  # Standard Deviation
    se_val <- sd_val / sqrt(n)  # Standard Error
    values_list <- x[[col]][!is.na(x[[col]])]  # List of non-missing values
    
    # Convert the list of values to a single string
    values_str <- paste(values_list, collapse = ", ")
    
    # Return a data frame for each group
    return(data.frame(mean = mean_val, std = sd_val, se = se_val, values = values_str, stringsAsFactors = FALSE))
  }
  
  # Apply the summary function to each group
  data_sum <- plyr::ddply(data, groupnames, .fun = summary_func, varname)
  
  return(data_sum)
}
```

```{r}
#### Normalize Synapses Count

# ATTENTION IN THIS NEW DF `Synapses` col refer to the Normalised counts

# Extract unique Brain IDs
brain_IDs <- unique(df_all$Brain.ID)

# Make a copy of df_all
df_norm <- df_all

# Initialize Normalised Synapses column with zeros
df_norm$`Normalised Synapses` <- 0

# Calculate normalized Synapses counts
for (ID in brain_IDs) {
  # Get the total synapses for the current brain ID in the 'leaf' regions
  tot_synapses <- df_all %>%
    filter((Brain.ID == ID) & (IsLeaf == "True")) %>% #True is read as stirng
    summarise(Total = sum(Synapses, na.rm = "True")) %>%
    pull(Total)
  
  if (is.na(tot_synapses) || (tot_synapses == 0)) {
    message(paste("\tATTENTION: brain", ID, "has no synapses."))
  } else {
    # Normalize synapses counts
    df_norm <- df_norm %>%
      mutate(`Normalised Synapses` = ifelse(Brain.ID == ID, Synapses / tot_synapses, `Normalised Synapses`))
  }
}

# call the normilsed Synapses col as just Synapses
df_norm = df_norm %>%
          mutate(Synapses = NULL) %>%
          rename(Synapses = `Normalised Synapses`)

```

```{r}
# Order of the x-axis of various plots
desired_order <- c("Uninjured", "1 weeks", "8 weeks")

# archteypes
archetypes = c(arch_a1, arch_a2, arch_a3, arch_a4)

# Plot the sifingicat ROI of a spefic archetypes
for (arch in archetypes){
  
  # Extract sifgcat ROI of this archetype
  ROI_significant_arch = unique(df_significant[df_significant$archetype == arch,]$region)
  
  if(length(ROI_significant_arch) == 0){ 
    print(paste0("No significatn ROI for ", arch))
    next
  }
  
  # Extarct values relatvie to the rois and refion inecjetion
  normalise_synapses = TRUE
  if(normalise_synapses == TRUE){
    df_ROIs = df_norm[(df_norm$`Region.Injection` == region_injection) &
                  (df_norm$ROI %in% ROI_significant_arch),
                  ]
  }
  else{
    df_ROIs = df_all[(df_all$`Region.Injection` == region_injection) &
                    (df_all$ROI %in% ROI_significant_arch),
                    ]
  }
  
  # calculate mean, std and sem for each ROI of SYNAPSES COUNT
  ds = data_summary(df_ROIs , 
                    varname="Synapses", 
                    groupnames=c("TimePoint", "Region.Injection", "ROI"))
  
  # calculate mean, std and sem for each ROI of DENSITY
  ds_density = data_summary(df_ROIs , 
                    varname="Cell.Density", 
                    groupnames=c("TimePoint", "Region.Injection", "ROI"))
  
  # Plot for each ROI
  for ( roi in ROI_significant_arch ){
    
    ### FOR SYNAPSES COUNT
  
    df_roi = ds %>% filter((ROI == roi))
    
    # Filter data for the current ROI
    df_roi <- df_roi %>%
              mutate(TimePoint = factor(TimePoint, levels = desired_order)) %>%
              arrange(TimePoint)
    
    # Parse the 'values' column to extract individual data points --> for jitter plot
    df_values <- df_roi %>%
      rowwise() %>%
      mutate(Synapses = strsplit(values, ", ")) %>%
      unnest(cols = Synapses) %>%
      mutate(Synapses = as.numeric(Synapses))
      
    
    # Create the LINEPLOTS with jitter dots
    plot_lineplot <- ggplot(df_roi, aes(x = TimePoint, y = mean, group = ROI)) +
      geom_line(color = "skyblue", size = 1) +  # Line plot for the mean values
      geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2, color = "red") +  # Error bars for SE
      geom_point(color = "blue") +  # Points for the mean values
      geom_jitter(data = df_values, aes(x = TimePoint, y = Synapses), width = 0, height = 0, color = "black", alpha = 0.5) +  # Jittered points for individual data
      labs(x = "Timepoint", y = "Mean Synapses Count", 
           title = paste0("Evolution of ROI synapses count\n", "ROI: ", df_roi$ROI[1], "\nInjection Region: ", df_roi$Region.Injection[1]))  # Axis labels and title
    
    # Create the BARPLOT with jitter dots
    plot_barplot <- ggplot(df_roi, aes(x = TimePoint, y = mean, fill = ROI)) +
      geom_col(fill = "skyblue",color = "black", position = position_dodge(width = 0.8), width = 0.7) +  # Bar plot for mean values
      geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2, color = "red", position = position_dodge(width = 0.8)) +  # Error bars for SE
      geom_jitter(data = df_values, aes(x = TimePoint, y = Synapses), width = 0, height = 0, color = "black", alpha = 0.7, size = 2) +  # Jittered points for individual data
      labs(x = "Timepoint", y = "Mean Synapses Count", 
           title = paste0("Evolution of ROI synapses count\nROI: ", df_roi$ROI[1], "\nInjection Region: ", df_roi$Region.Injection[1])) +  # Axis labels and title
      #theme_minimal() +  # Minimal theme for clarity
      theme(legend.position = "none")  # Remove legend if not needed
    
    
    
    
    
    ### FOR DENSITY
    
    df_roi = ds_density %>% filter((ROI == roi))
    
    # Filter data for the current ROI
    df_roi <- df_roi %>%
              mutate(TimePoint = factor(TimePoint, levels = desired_order)) %>%
              arrange(TimePoint)
    
    # Parse the 'values' column to extract individual data points --> for jitter plot
    df_values <- df_roi %>%
      rowwise() %>%
      mutate(Cell.Density = strsplit(values, ", ")) %>%
      unnest(cols = Cell.Density) %>%
      mutate(Cell.Density = as.numeric(Cell.Density))
      
    
    # Create the LINEPLOTS with jitter dots
    plot_lineplot_density <- ggplot(df_roi, aes(x = TimePoint, y = mean, group = ROI)) +
      geom_line(color = "skyblue", size = 1) +  # Line plot for the mean values
      geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2, color = "red") +  # Error bars for SE
      geom_point(color = "blue") +  # Points for the mean values
      geom_jitter(data = df_values, aes(x = TimePoint, y = Cell.Density), width = 0, height = 0, color = "black", alpha = 0.5) +  # Jittered points for individual data
      labs(x = "Timepoint", y = "Mean Density", 
           title = paste0("Evolution of ROI Density\n", "ROI: ", df_roi$ROI[1], "\nInjection Region: ", df_roi$Region.Injection[1]))  # Axis labels and title
    
    
    
    
    ### SAVE
    
    # Arrange the plots in a single row
    plot = grid.arrange(plot_lineplot, plot_barplot, plot_lineplot_density, ncol = 3)

    # Print the plot
    print(plot)
    
    #Save the figure
    roi_clean <- gsub("[, :/]", "", roi)
    path_plot = file.path(lineplots_folder, arch, paste0(roi_clean, ".pdf"))
    ggsave(path_plot, plot, width = 15, height = 7)
    
  
  }

}

```
